{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJJEczSzQzW5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIy0mYgvQwP9",
        "outputId": "e170582c-a8c0-4fb7-cbef-bf598e244e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.12-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozendict>=2.3.4\n",
            "  Downloading frozendict-2.3.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.8/112.8 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptography>=3.3.2\n",
            "  Downloading cryptography-39.0.2-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html5lib>=1.1\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beautifulsoup4>=4.11.1\n",
            "  Downloading beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.4\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.9/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.9/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.9/dist-packages (from yfinance) (4.9.2)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/dist-packages (from html5lib>=1.1->yfinance) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26->yfinance) (1.26.15)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Installing collected packages: appdirs, html5lib, frozendict, charset-normalizer, beautifulsoup4, requests, cryptography, yfinance\n",
            "  Attempting uninstall: html5lib\n",
            "    Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.9.3\n",
            "    Uninstalling beautifulsoup4-4.9.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.9.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed appdirs-1.4.4 beautifulsoup4-4.11.2 charset-normalizer-3.1.0 cryptography-39.0.2 frozendict-2.3.5 html5lib-1.1 requests-2.28.2 yfinance-0.2.12\n"
          ]
        }
      ],
      "source": [
        "! pip install yfinance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gmRt37qRJGk"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA_sDx12RH9g"
      },
      "outputs": [],
      "source": [
        "# estrutura de dados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# gráficos\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "# dados\n",
        "import yfinance as yf\n",
        "\n",
        "# modelo\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras import initializers\n",
        "from keras import callbacks\n",
        "# métricas\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error, \n",
        "    mean_squared_error, \n",
        "    r2_score, \n",
        "    mean_absolute_percentage_error\n",
        ")\n",
        "\n",
        "# escalonadores\n",
        "from sklearn.preprocessing import *\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# seeds\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5gTebXeRptV"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5UZ1X0iRpIW"
      },
      "outputs": [],
      "source": [
        "#from scipy import show_config\n",
        "#from sklearn.utils import validation\n",
        "def get_train_test_split_scal(\n",
        "    df,\n",
        "    target,\n",
        "    train_size,\n",
        "    window_size,\n",
        "    normalize,\n",
        "    scaler\n",
        "):\n",
        "  df.pop('Adj Close'), df.pop('Volume')\n",
        "  training_data_len = int(np.ceil(len(df) * train_size))\n",
        "  train_data = df[:training_data_len].copy()\n",
        "  test_data = df[training_data_len-window_size:].copy()\n",
        "\n",
        "  x_train = list()\n",
        "  y_train = list()\n",
        "  x_test = list()\n",
        "  y_test = list()\n",
        "\n",
        "  if normalize:\n",
        "    global scaler_high_test, y_test_normalized\n",
        "    scaler_open_train = scaler()\n",
        "    scaler_high_train = scaler()\n",
        "    scaler_low_train = scaler()\n",
        "    scaler_close_train = scaler()\n",
        "    scaler_open_test = scaler()\n",
        "    scaler_high_test = scaler()\n",
        "    scaler_low_test = scaler()\n",
        "    scaler_close_test = scaler()\n",
        "\n",
        "    train_data['Open'] = scaler_open_train.fit_transform(train_data['Open'].values.reshape(-1,1))\n",
        "    train_data['High'] = scaler_high_train.fit_transform(train_data['High'].values.reshape(-1,1))\n",
        "    train_data['Low'] = scaler_low_train.fit_transform(train_data['Low'].values.reshape(-1,1))\n",
        "    train_data['Close'] = scaler_close_train.fit_transform(train_data['Close'].values.reshape(-1,1))\n",
        "\n",
        "    test_data['Open'] = scaler_open_test.fit_transform(test_data['Open'].values.reshape(-1,1))\n",
        "    test_data['High'] = scaler_high_test.fit_transform(test_data['High'].values.reshape(-1,1))\n",
        "    test_data['Low'] = scaler_low_test.fit_transform(test_data['Low'].values.reshape(-1,1))\n",
        "    test_data['Close'] = scaler_close_test.fit_transform(test_data['Close'].values.reshape(-1,1))\n",
        "\n",
        "    y_test_normalized = np.array(scaler_high_test.fit_transform(df[target][training_data_len:].copy().values.reshape(-1,1)))\n",
        "\n",
        "  # end if\n",
        "\n",
        "  for i in range(window_size, len(train_data)):\n",
        "    x_train.append(train_data[i-window_size:i])\n",
        "    y_train.append(train_data[target][i])\n",
        "          \n",
        "  for i in range(window_size, len(test_data)):\n",
        "    x_test.append(test_data[i-window_size:i])\n",
        "\n",
        "  x_test = np.array(x_test)\n",
        "  x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "  y_test = np.array(df[target][training_data_len:].copy())\n",
        "\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "def get_pred(\n",
        "    model,\n",
        "    x_test,\n",
        "    normalize,\n",
        "    shuffle=True,\n",
        "    batch=0  \n",
        "):\n",
        "  if shuffle == False:\n",
        "    y_pred = model.predict(x_test, batch_size=batch)\n",
        "  else:\n",
        "    y_pred = model.predict(x_test)\n",
        "  if normalize:\n",
        "    y_pred = scaler_high_test.inverse_transform(y_pred)\n",
        "  return y_pred\n",
        "\n",
        "def get_compare(\n",
        "    df,\n",
        "    target,\n",
        "    train_size,\n",
        "    window_size,\n",
        "    y_pred\n",
        "):\n",
        "  data = df[target].copy()\n",
        "\n",
        "  training_data_len = int(np.ceil(len(df) * train_size))\n",
        "  train_data = data[:training_data_len]\n",
        "  test_data = data[training_data_len-window_size:]\n",
        "\n",
        "  ma7 = list()\n",
        "  for i in range(training_data_len, len(data)):\n",
        "    n = data[i]\n",
        "    for c in range(1, 7):\n",
        "      n += data[i-c]\n",
        "    n = n/7\n",
        "    ma7.append(n)\n",
        "  \n",
        "  validation = pd.DataFrame(data[training_data_len:])\n",
        "  validation['Predictions'] = y_pred\n",
        "  random_walk = data[-(len(validation)+1):-1].values\n",
        "  validation['Random Walk'] = random_walk\n",
        "  validation['MA7'] = ma7\n",
        "\n",
        "  return validation\n",
        "\n",
        "def get_scores(\n",
        "    df_validation,\n",
        "    y_test='High',\n",
        "    y_pred='Predictions',\n",
        "    random_walk='Random Walk',\n",
        "    ma7='MA7'\n",
        "):\n",
        "\n",
        "  metrics = list()\n",
        "  comp_metrics = list()\n",
        "  columns = list(df_validation.columns)\n",
        "\n",
        "  for i in range(1, 4):\n",
        "    mae_test = mean_absolute_error(df_validation[y_test], df_validation[columns[i]])\n",
        "    mse_test = mean_squared_error(df_validation[y_test], df_validation[columns[i]])\n",
        "    rmse_test = mse_test ** 0.5\n",
        "    r2_test = r2_score(df_validation[y_test], df_validation[columns[i]])\n",
        "    mape_test = 100 * mean_absolute_percentage_error(df_validation[y_test], df_validation[columns[i]])\n",
        "\n",
        "    metrics = [f'{mae_test:.2f}', f'{mape_test:.2f}', f'{mse_test:.2f}', f'{rmse_test:.2f}', f'{r2_test:.2f}']\n",
        "    comp_metrics.append(metrics.copy())\n",
        "    metrics.clear()\n",
        "\n",
        "  df_metrics = pd.DataFrame(comp_metrics, index=['Modelo', 'Random Walk', 'Moving Average 7'], columns=['MAE', 'MAPE', 'MSE', 'RMSE', 'R²'])\n",
        "  return df_metrics\n",
        "\n",
        "def show_save_results(setup_name, ticker, df_metrics):\n",
        "  print(f\"Resultados {setup_name} para {ticker}\")\n",
        "  print(df_metrics)\n",
        "  df_metrics.to_csv(f'Comparação de métricas entre o modelo{setup_name}, média móvel de 7 dias e random walk para a série {ticker}.csv')\n",
        "\n",
        "def save_fig(\n",
        "    setup_name,\n",
        "    df,\n",
        "    target,\n",
        "    train_size,\n",
        "    epochs,\n",
        "    historic,\n",
        "    ticker,\n",
        "    validation,\n",
        "    loss=False,\n",
        "    full=False,\n",
        "    predictions=False,\n",
        "    interval=False,\n",
        "    i_start=0,\n",
        "    i_end=0\n",
        "):\n",
        "  mpl.style.use('seaborn-darkgrid')\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure(figsize=(16,6))\n",
        "  \n",
        "  if loss: \n",
        "    plt.plot(np.arange(0,epochs), historic.history[\"loss\"], label=\"train_loss\", color='#ADBF97')\n",
        "    plt.plot(np.arange(0,epochs), historic.history['val_loss'], label=\"val_loss\", color='blue')\n",
        "    plt.title(f\"Perda de treinamento da série {ticker}\")\n",
        "    plt.xlabel(\"Amostra\")\n",
        "    plt.ylabel(\"Perda\")\n",
        "    plt.legend(prop={'size':16})\n",
        "    fig = plt.gcf()\n",
        "    plt.show()\n",
        "    fig.savefig(f\"Perda de treinamento do modelo{setup_name} da série {ticker}.png\", format='png')\n",
        "\n",
        "  if full:\n",
        "\n",
        "    data = df[target]\n",
        "    plt.title(f'Previsão do modelo {setup_name} em R$ para o preço de {target} da série {ticker}')\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('Preço de fechamento (R$)')\n",
        "    plt.plot(data, color='#ADBF97')\n",
        "    plt.plot(validation[target], color='blue')\n",
        "    plt.plot(validation[['Predictions']], color='orange')\n",
        "    #plt.plot(validation['Random Walk'], color='red')\n",
        "    #plt.plot(validation['MA7'], color='green')\n",
        "    plt.legend(['Train', 'Test', 'Predictions'], loc='best', prop={'size':16})\n",
        "    fig = plt.gcf()\n",
        "    plt.show()\n",
        "    fig.savefig(f'Grafico de treino e previsão do modelo {setup_name} em R$ para o preço de {target} da série {ticker}.png', format='png')\n",
        "\n",
        "  if predictions:\n",
        "    plt.title(f'Previsão do modelo {setup_name} em R$ para o preço de {target} da série {ticker}')\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('Preço de alta (R$)')\n",
        "    plt.plot(validation[target], color='blue')\n",
        "    plt.plot(validation[['Predictions']], color='orange')\n",
        "    #plt.plot(validation['Random Walk'], color='red')\n",
        "    #plt.plot(validation['MA7'], color='green')\n",
        "    plt.legend(['Valor real', 'Predições'], loc='best', prop={'size':16})\n",
        "    fig = plt.gcf()\n",
        "    plt.show()\n",
        "    fig.savefig(f'Grafico de previsão do modelo {setup_name} em R$ para o preço de {target} da série {ticker}.png', format='png')\n",
        "\n",
        "  if interval:\n",
        "    plt.title(f'Previsão do modelo {setup_name} em R$ para o preço de {target} da série {ticker}')\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('Preço de alta (R$)')\n",
        "    plt.plot(validation[[target]][i_start:i_end], color='blue')\n",
        "    plt.plot(validation[['Predictions']][i_start:i_end], color='orange')\n",
        "    plt.plot(validation['Random Walk'][i_start:i_end], color='red')\n",
        "    plt.plot(validation['MA7'][i_start:i_end], color='green')\n",
        "    plt.legend(['Valor real', 'Predições', 'Random Walk', 'Moving average 7'], loc='best', prop={'size':16})\n",
        "    fig = plt.gcf()\n",
        "    plt.show()\n",
        "    fig.savefig(f'Grafico de {i_end-i_start} dias da previsão do modelo {setup_name} em R$ para o preço de {target} da série {ticker}.png', format='png')\n",
        "  \n",
        "  return\n",
        "\n",
        "def full_experiment(\n",
        "    experiment_name,\n",
        "    ticker,\n",
        "    start_date,\n",
        "    end_date,\n",
        "    custom_model,\n",
        "    shuffle,\n",
        "    target='High',\n",
        "    train_size=0.7,\n",
        "    window_size=3,\n",
        "    normalize=False,\n",
        "    scaler=MinMaxScaler,\n",
        "    epochs=300,\n",
        "    batch=100,\n",
        "    loss=False,\n",
        "    full=False,\n",
        "    predictions=False,\n",
        "    interval=False,\n",
        "    i_start=0,\n",
        "    i_end=0\n",
        "):\n",
        "  # Load data\n",
        "  df = yf.download(ticker, start=start_date, end=end_date)\n",
        "  # split train and test and normalize data\n",
        "  if normalize:\n",
        "    x_train, y_train, x_test, y_test = get_train_test_split_scal(df, target, train_size, window_size, normalize, scaler)\n",
        "  else:\n",
        "    x_train, y_train, x_test, y_test = get_train_test_split_scal(df, target, train_size, window_size)\n",
        "  # create model\n",
        "  if shuffle == False:\n",
        "    model = custom_model(x_train, batch)\n",
        "  else:\n",
        "    model = custom_model(x_train)\n",
        "  # train model\n",
        "  early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "  global historic\n",
        "  if normalize:\n",
        "    if shuffle == False:\n",
        "      historic = model.fit(x_train, y_train, epochs=epochs, batch_size=batch, validation_data = (x_test, y_test_normalized), verbose=1, shuffle=False)\n",
        "    else:\n",
        "      historic = model.fit(x_train, y_train, epochs=epochs, batch_size=batch, validation_data = (x_test, y_test_normalized), verbose=1)\n",
        "  else:\n",
        "      historic = model.fit(x_train, y_train, epochs=epochs, batch_size=batch, validation_data = (x_test, y_test), verbose=1)\n",
        "  # get predictions to test and renormalize\n",
        "  if normalize:\n",
        "    if shuffle == False:\n",
        "      y_pred = get_pred(model, x_test, normalize, shuffle=shuffle, batch=batch)\n",
        "    else:\n",
        "      y_pred = get_pred(model, x_test, normalize)\n",
        "  # get predictions to test\n",
        "  else:\n",
        "    y_pred = get_pred(model, x_test)\n",
        "  # create compare\n",
        "  validation = get_compare(df, target, train_size, window_size, y_pred)\n",
        "  # compare predictions and real data\n",
        "  df_metrics = get_scores(validation)\n",
        "  # show and save results\n",
        "  show_save_results(experiment_name, ticker, df_metrics)\n",
        "  if loss:\n",
        "    save_fig(experiment_name, df, target, train_size, epochs, historic, ticker, validation, loss=True)\n",
        "  if full:\n",
        "    save_fig(experiment_name, df, target, train_size, epochs, historic, ticker, validation, full=True)\n",
        "  if predictions:\n",
        "    save_fig(experiment_name, df, target, train_size, epochs, historic, ticker, validation, predictions=True)\n",
        "  if interval:\n",
        "    save_fig(experiment_name, df, target, train_size, epochs, historic, ticker, validation, interval=True, i_start=i_start, i_end=i_end)\n",
        "  return experiment_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sYNGBO9KGf7"
      },
      "outputs": [],
      "source": [
        "# Setup 1_0(LSTM)\n",
        "def LSTM_setup1_0(x_train):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, input_shape= (x_train.shape[1], x_train.shape[2])))\n",
        "  model.add(LSTM(100, return_sequences=False))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup1_0\",\n",
        "  ticker='ABEV3.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup1_0,\n",
        "  shuffle=True,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=100,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")\n",
        "#executado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59J7Ay_6hXAJ"
      },
      "outputs": [],
      "source": [
        "# Setup 2_0(LSTM)\n",
        "def LSTM_setup2_0(x_train, batch):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, batch_input_shape=(batch, x_train.shape[1], x_train.shape[2]), stateful=True))\n",
        "  model.add(LSTM(100, return_sequences=False, stateful=True))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup2_0\",\n",
        "  ticker='ABEV3.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup2_0,\n",
        "  shuffle=False,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")\n",
        "#executado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uU6VaKSgBcFA"
      },
      "outputs": [],
      "source": [
        "# Setup 1_1 (LSTM)\n",
        "def LSTM_setup1_1(x_train):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "  model.add(LSTM(100, return_sequences=False))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup1_1\",\n",
        "  ticker='BBAS3.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup1_1,\n",
        "  shuffle=True,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")\n",
        "#executado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KoH3pZUDMI_"
      },
      "outputs": [],
      "source": [
        "# Setup 2_1 (LSTM)\n",
        "def LSTM_setup2_1(x_train, batch):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, batch_input_shape=(batch, x_train.shape[1], x_train.shape[2]), stateful=True))\n",
        "  model.add(LSTM(100, return_sequences=False, stateful=True))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup2_1\",\n",
        "  ticker='BBAS3.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup2_1,\n",
        "  shuffle=False,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")\n",
        "#executado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UOZ6Y-5LkQ-"
      },
      "outputs": [],
      "source": [
        "# Setup 1_2 (LSTM)\n",
        "def LSTM_setup1_2(x_train):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "  model.add(LSTM(100, return_sequences=False))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup1_2\",\n",
        "  ticker='BBDC4.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup1_2,\n",
        "  shuffle=True,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")\n",
        "#executado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 2_2 (LSTM)\n",
        "def LSTM_setup2_2(x_train, batch):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, batch_input_shape=(batch, x_train.shape[1], x_train.shape[2]), stateful=True))\n",
        "  model.add(LSTM(100, return_sequences=False, stateful=True))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup2_2\",\n",
        "  ticker='BBDC4.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup2_2,\n",
        "  shuffle=False,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")\n",
        "#excutado"
      ],
      "metadata": {
        "id": "EghI_AjDG0dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 1_3 (LSTM)\n",
        "def LSTM_setup1_3(x_train):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "  model.add(LSTM(100, return_sequences=False))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup1_3\",\n",
        "  ticker='TAEE11.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup1_3,\n",
        "  shuffle=True,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")\n",
        "#executado"
      ],
      "metadata": {
        "id": "e7Pye0V9HFOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuIl4YS_Vw98"
      },
      "outputs": [],
      "source": [
        "# Setup 2_3 (LSTM)\n",
        "def LSTM_setup2_3(x_train, batch):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, batch_input_shape=(batch, x_train.shape[1], x_train.shape[2]), stateful=True))\n",
        "  model.add(LSTM(100, return_sequences=False, stateful=True))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup2_3\",\n",
        "  ticker='TAEE11.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup2_3,\n",
        "  shuffle=False,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")\n",
        "#executado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup 1_4 (LSTM)\n",
        "def LSTM_setup1_4(x_train):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "  model.add(LSTM(100, return_sequences=False))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup1_4\",\n",
        "  ticker='CMIG4.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup1_4,\n",
        "  shuffle=True,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")"
      ],
      "metadata": {
        "id": "JSAunTXwHcS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2P4kIPdbBW_"
      },
      "outputs": [],
      "source": [
        "# Setup 2_4 (LSTM)\n",
        "def LSTM_setup2_4(x_train, batch):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, return_sequences=True, batch_input_shape=(batch, x_train.shape[1], x_train.shape[2]), stateful=True))\n",
        "  model.add(LSTM(100, return_sequences=False, stateful=True))\n",
        "  model.add(Dense(25))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "results = full_experiment(\n",
        "  experiment_name = \"LSTM_setup2_4\",\n",
        "  ticker='CMIG4.SA',\n",
        "  start_date='2008-01-01',\n",
        "  end_date='2022-12-31',\n",
        "  custom_model=LSTM_setup2_4,\n",
        "  shuffle=False,\n",
        "  normalize=True,\n",
        "  scaler=MinMaxScaler,\n",
        "  epochs=300,\n",
        "  batch=2,\n",
        "  target='High',\n",
        "  train_size=0.7,\n",
        "  window_size=3,\n",
        "  loss=True,\n",
        "  full=True,\n",
        "  predictions=True,\n",
        "  interval=True,\n",
        "  i_start=15,\n",
        "  i_end=150\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}